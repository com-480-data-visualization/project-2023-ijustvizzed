@misc{hershey2021complete,
  title = {Complete {{Donald Trump Tweets Archive}}},
  author = {Hershey, Mark},
  date = {2021-01-10},
  url = {https://github.com/MarkHershey/CompleteTrumpTweetsArchive},
  version = {Git commit 8be27c4}
}

@online{mikolov2013distributed,
  title = {Distributed {{Representations}} of {{Words}} and {{Phrases}} and Their {{Compositionality}}},
  author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  date = {2013-10-16},
  number = {arXiv:1310.4546},
  eprint = {arXiv:1310.4546},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/1310.4546},
  urldate = {2023-06-02},
  abstract = {The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of "Canada" and "Air" cannot be easily combined to obtain "Air Canada". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/flo/nextcloud/Uni/zotero/zotero-files/2013_Mikolov_et_al_Distributed_Representations_of_Words_and_Phrases_and_their_Compositionality.pdf;/home/flo/nextcloud/Uni/zotero/zotero-system/storage/RECARHZG/1310.html}
}

@online{mikolov2013efficient,
  title = {Efficient {{Estimation}} of {{Word Representations}} in {{Vector Space}}},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  date = {2013-09-06},
  number = {arXiv:1301.3781},
  eprint = {arXiv:1301.3781},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/1301.3781},
  urldate = {2023-06-02},
  abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/home/flo/nextcloud/Uni/zotero/zotero-files/2013_Mikolov_et_al_Efficient_Estimation_of_Word_Representations_in_Vector_Space.pdf;/home/flo/nextcloud/Uni/zotero/zotero-system/storage/3XFHF9LV/1301.html}
}

@article{morales2021impact,
  title = {The {{Impact}} of 280 {{Characters}}: {{An Analysis}} of {{Trump}}’s {{Tweets}} and {{Television News Through}} the {{Lens}} of {{Agenda Building}}},
  shorttitle = {The {{Impact}} of 280 {{Characters}}},
  author = {Morales, Erendira Abigail and Schultz, Cindy J. Price and Landreville, Kristen D.},
  date = {2021-03},
  journaltitle = {Electronic News},
  shortjournal = {Electronic News},
  volume = {15},
  number = {1-2},
  pages = {21--37},
  issn = {1931-2431, 1931-244X},
  doi = {10.1177/19312431211028610},
  url = {http://journals.sagepub.com/doi/10.1177/19312431211028610},
  urldate = {2023-06-02},
  abstract = {Twitter impacts what is covered by journalists, which affects what viewers think is important. This article explores the association between Trump’s tweets and cable and network television news coverage through the theoretical framework of agenda building. During a 3-week period in January 2020, a content analysis of story topics and publication times of Fox News, CNN, ABC, and NBC (N = 1,436) was conducted in conjunction with Trump’s tweets (N = 277). The findings showed a strong correlation between Fox News and @realDonaldTrump ’s tweets and a moderate correlation with CNN. About half of Trump’s tweets reflected Fox News stories, hosts, or guests. More than 40\% of news stories mentioned Trump, while his tweets were in stories at least 10\% of the time. The results showed that Trump and Fox News had a strong influence over agenda building in the United States’ television news landscape.},
  langid = {english},
  file = {/home/flo/nextcloud/Uni/zotero/zotero-files/2021_Morales_et_al_The_Impact_of_280_Characters.pdf}
}

@online{simonsen20234682,
  title = {4682 Episodes of {{The Alex Jones Show}} (15875 Hours) Transcribed},
  author = {Simonsen, Erlend},
  date = {2023-03-22},
  url = {https://www.reddit.com/r/datasets/comments/11yyoth/4682_episodes_of_the_alex_jones_show_15875_hours/}
}

@misc{simonsen2023infowars,
  title = {Infowars},
  author = {Simonsen, Erlend},
  date = {2023-04-18},
  url = {https://github.com/Fudge/infowars},
  version = {Git commit 4b5e83a}
}

@misc{thompson2022all,
  title = {All the {{News}} 2.0 -- 2.7 Million News Articles and Essays from 27 {{American}} Publications},
  author = {Thompson, Andrew},
  date = {2022-07-09},
  url = {https://components.one/datasets/all-the-news-2-news-articles-dataset/}
}
